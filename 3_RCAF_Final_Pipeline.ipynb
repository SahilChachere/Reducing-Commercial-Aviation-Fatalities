{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3 RCAF_Final Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwgN9zi8nfyA"
      },
      "source": [
        "# **Fetch dataset from kaggle to google colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yieD03fKjySc"
      },
      "source": [
        "#kaggle API token\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbwCslryksCG",
        "outputId": "63622253-a53d-432c-b830-5791168ff8fe"
      },
      "source": [
        "#upgrade kaggle library\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 19.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 12.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 14.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=e38aed3cf25e5341cfe0ad9da0aef242add2ac69b5c1d1f27dd9da323e57b5be\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zgViV3UjPVn",
        "outputId": "f9d9daad-c646-426b-a229-f24ffe59f484"
      },
      "source": [
        "#download rcaf dataset to colab\n",
        "!kaggle competitions download -c reducing-commercial-aviation-fatalities"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading reducing-commercial-aviation-fatalities.zip to /content\n",
            " 99% 2.12G/2.13G [00:32<00:00, 71.3MB/s]\n",
            "100% 2.13G/2.13G [00:33<00:00, 69.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vr86SkylTA_",
        "outputId": "b3b65de8-cfef-4253-bd68-0885ff28d6c3"
      },
      "source": [
        "#unzip dataset and remove zip file\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  reducing-commercial-aviation-fatalities.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLi41xlVlAi4"
      },
      "source": [
        "# **Improting libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwK-pfnamK89"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, iirnotch, lfilter, sosfilt\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TziI6h_HlE-h"
      },
      "source": [
        "**Load pre-trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YUoJtqNJK3M"
      },
      "source": [
        "#loaded trained LightGBM model\n",
        "model = joblib.load('/content/drive/MyDrive/applied aic/case studies/rcaf/models/lgbm_model.pkl')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwdVevWklHwi"
      },
      "source": [
        "**Load train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQJIC4syJ6Gf"
      },
      "source": [
        "#load train data\n",
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5-Qitnigshy"
      },
      "source": [
        "try:\n",
        "  y = train.event\n",
        "  X = train.drop(['event'], axis=1)\n",
        "except Exception as ex:\n",
        "  print(ex)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5QC3UcglN1Q"
      },
      "source": [
        "**Load test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucMe8_acufCx"
      },
      "source": [
        "#load test data\n",
        "X = pd.read_csv('test.csv', nrows=100000)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duANvzWzdhrn"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFXE4fJ-dRfr"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def derive_eeg_features(df):\n",
        "  \"\"\"\n",
        "  deriving eeg features from existing eeg features\n",
        "  \"\"\"\n",
        "\n",
        "  data = df\n",
        "  #deriving new eeg features according to Longitudinal-Traverse Bipolar method\n",
        "  #Left electrodes traverse(Fp1 to O1)\n",
        "  data['eeg_fp1-f7'] = data['eeg_fp1']-data['eeg_f7']\n",
        "  data['eeg_f7-t3'] = data['eeg_f7']-data['eeg_t3']\n",
        "  data['eeg_t3-t5'] = data['eeg_t3']-data['eeg_t5']\n",
        "  data['eeg_t5-o1'] = data['eeg_t5']-data['eeg_o1']\n",
        "  data['eeg_fp1-f3'] = data['eeg_fp1']-data['eeg_f3']\n",
        "  data['eeg_f3-c3'] = data['eeg_f3']-data['eeg_c3']\n",
        "  data['eeg_c3-p3'] = data['eeg_c3']-data['eeg_p3']\n",
        "  data['eeg_p3-o1'] = data['eeg_p3']-data['eeg_o1']\n",
        "  #Central electrodes traverse (T3 to T4)\n",
        "  data['eeg_t3-c3'] = data['eeg_t3']-data['eeg_c3']\n",
        "  data['eeg_c3-cz'] = data['eeg_c3']-data['eeg_cz']\n",
        "  data['eeg_cz-c4'] = data['eeg_cz']-data['eeg_c4']\n",
        "  data['eeg_c4-t4'] = data['eeg_c4']-data['eeg_t4']\n",
        "  #Right electrodes traverse (FP2 to O2)\n",
        "  data['eeg_fp2-f8'] = data['eeg_fp2']-data['eeg_f8']\n",
        "  data['eeg_f8-t4'] = data['eeg_f8']-data['eeg_t4']\n",
        "  data['eeg_t4-t6'] = data['eeg_t4']-data['eeg_t6']\n",
        "  data['eeg_t6-o2'] = data['eeg_t6']-data['eeg_o2']\n",
        "  data['eeg_fp2-f4'] = data['eeg_fp2']-data['eeg_f4']\n",
        "  data['eeg_f4-c4'] = data['eeg_f4']-data['eeg_c4']\n",
        "  data['eeg_c4-p4'] = data['eeg_c4']-data['eeg_p4']\n",
        "  data['eeg_p4-o2'] = data['eeg_p4']-data['eeg_o2']\n",
        "\n",
        "  data = data.drop(columns=['eeg_fp1', 'eeg_f7', 'eeg_f8','eeg_t4', 'eeg_t6', 'eeg_t5', 'eeg_t3', 'eeg_fp2', 'eeg_o1', 'eeg_p3',\n",
        "                        'eeg_pz', 'eeg_f3', 'eeg_fz', 'eeg_f4', 'eeg_c4', 'eeg_p4', 'eeg_poz',\n",
        "                        'eeg_c3', 'eeg_cz', 'eeg_o2'], axis=1)\n",
        "               \n",
        "  return data\n",
        "\n",
        "def signal_filter(signal, low=None, high=None, powerline=60, fs=None, order=None):\n",
        "    \"\"\"\n",
        "    references-\n",
        "    #https://towardsdatascience.com/getting-the-right-beat-e18acd48b8c1\n",
        "    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.sosfilt.html#scipy.signal.sosfilt\n",
        "    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.lfilter.html\n",
        "    \n",
        "    parameters-\n",
        "    signal: raw signal data\n",
        "    low: minimum required frequency ex. 5Hz or 50bpm\n",
        "    high: maximum required frequency ex. 10Hz or 100bpm\n",
        "    powerline: default Alternate current frequency 60Hz for USA\n",
        "    fs: sampling rate\n",
        "    order: order of the filter\n",
        "    \n",
        "    description-\n",
        "    this is signal filter function, it filters raw signal data using scipy module.\n",
        "    this function removes mainly 3 noise types - very high frequency, very low frequency and power fluctuations.\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    #nyquist frequency\n",
        "    nyq=0.5*fs\n",
        "    \n",
        "    #1 handling high frequency noise\n",
        "    normallized_high = high/nyq\n",
        "    sos1 = butter(order, normallized_high, btype='high', analog=False, output='sos')\n",
        "    x = sosfilt(sos1, signal)\n",
        "    \n",
        "    #2 handling low frequency noise\n",
        "    normallized_low = low/nyq\n",
        "    sos2 = butter(order, normallized_low, btype='low', analog=False, output='sos')\n",
        "    y = sosfilt(sos2, x)\n",
        "    \n",
        "    #3 handling power fluctuations\n",
        "    freq=powerline/nyq\n",
        "    f, e = iirnotch(freq, 30)\n",
        "    filtered_signal = lfilter(f, e, y)\n",
        "    \n",
        "    \n",
        "    return filtered_signal\n",
        "\n",
        "def remove_redundant_columns(df):\n",
        "  \"\"\"\n",
        "  remove redundat columns from dataframe\n",
        "  \"\"\"\n",
        "  #test data has id column\n",
        "  if 'id' in df:\n",
        "    df = df.drop(columns=['ecg', 'gsr', 'r', 'crew', 'experiment', 'time', 'seat', 'id'], axis=1)\n",
        "  else:\n",
        "    df = df.drop(columns=['ecg', 'gsr', 'r', 'crew', 'experiment', 'time', 'seat'], axis=1)\n",
        "  return df\n",
        "\n",
        "def standardize(df):\n",
        "  \"\"\"\n",
        "  standardize columns and return as pandas dataframe\n",
        "  \"\"\"\n",
        "  standardized = StandardScaler()\n",
        "  df = standardized.fit_transform(df)\n",
        "\n",
        "  return pd.DataFrame(df)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efIIi5hMb7bR",
        "outputId": "f3bf978d-6d78-47fc-cd34-27857cecfd40"
      },
      "source": [
        "def pipeline(X):\n",
        "  \"\"\"\n",
        "  fetaure engineering pipeline used for train and test data during prediction\n",
        "  \"\"\"\n",
        "  #deepcopy of original dataframe\n",
        "  df = copy.deepcopy(X)\n",
        "\n",
        "  #memory optimization\n",
        "  df = reduce_mem_usage(df)\n",
        "\n",
        "  #derive eeg features\n",
        "  df = derive_eeg_features(df)\n",
        "\n",
        "  #filter ecg signal\n",
        "  filtered_ecg_signal = signal_filter(df.ecg, low=0.5, high=2, fs=1000, order=5)\n",
        "  df['filtered_ecg_signal'] = filtered_ecg_signal\n",
        "  \n",
        "  #filter gsr signal\n",
        "  filtered_gsr_signal = signal_filter(df.gsr, low=0.01, high=0.18, fs=1000, order=5)\n",
        "  df['filtered_gsr_signal'] = filtered_gsr_signal\n",
        "  \n",
        "  #filter respiration sigal\n",
        "  filtered_respiration_signal = signal_filter(df.r, low=0.01, high=0.16, fs=1500, order=5)\n",
        "  df['filtered_respiration_signal'] = filtered_respiration_signal\n",
        "  \n",
        "  #remove redundant columns\n",
        "  df = remove_redundant_columns(df)\n",
        "  \n",
        "  #standardization\n",
        "  df = standardize(df)\n",
        "\n",
        "  return df\n",
        "\n",
        "df = pipeline(X)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 21.36 MB\n",
            "Memory usage after optimization is: 5.25 MB\n",
            "Decreased by 75.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrSRGgGlu3e3"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNO583Hdetk"
      },
      "source": [
        "**Prediction on test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MxA9-z8odEH",
        "outputId": "87dbb04c-84cd-4f54-86fc-3f7b7ed032e5"
      },
      "source": [
        "#prediction without labels\n",
        "def function1(df):  \n",
        "  \"\"\"\n",
        "  prediction on test data without any labels\n",
        "  \"\"\"\n",
        "  #get random sample from dataframe\n",
        "  sample_row = random.sample(range(0,df.shape[0]),1)\n",
        "  data = df.iloc[sample_row]\n",
        "  proba=model.predict_proba(df.iloc[sample_row])\n",
        "  final_pred=np.argmax(proba,axis=1)\n",
        "\n",
        "  if final_pred == 0:\n",
        "    print('Predicted cognitive state: Baseline or No event')\n",
        "  elif final_pred == 1:\n",
        "    print('Predicted cognitive state: Surprised or Startle')\n",
        "  elif final_pred == 2:\n",
        "    print('Predicted cognitive state: Channelized attention')\n",
        "  else:\n",
        "    print('Predicted cognitive state: Diverted attention')\n",
        "\n",
        "pred = function1(df)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted cognitive state: Baseline or No event\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0tuV3j2dkyL"
      },
      "source": [
        "**Predicition on labelled data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v0SP7O1gWOh",
        "outputId": "6dfbd904-c939-4123-d898-584906f72a3b"
      },
      "source": [
        "#prediction with labels\n",
        "def function2(df, y):\n",
        "  \"\"\"\n",
        "  prediction on cross validation data with labels avaialable.\n",
        "  \"\"\"\n",
        "  #get random sample from dataframe\n",
        "  sample_row = random.sample(range(0,df.shape[0]),1)\n",
        "  data = df.iloc[sample_row]\n",
        "  proba=model.predict_proba(df.iloc[sample_row])\n",
        "\n",
        "  final_pred=np.argmax(proba,axis=1)\n",
        "  if final_pred == 0:\n",
        "    print('Predicted cognitive state: Baseline or No event')\n",
        "  elif final_pred == 1:\n",
        "    print('Predicted cognitive state: Surprised or Startle')\n",
        "  elif final_pred == 2:\n",
        "    print('Predicted cognitive state: Channelized attention')\n",
        "  else:\n",
        "    print('Predicted cognitive state: Diverted attention')\n",
        "\n",
        "  ground_truth = y.iloc[sample_row].values\n",
        "  if ground_truth == 'A':\n",
        "    print('Actual cognitive state: Baseline or No event')\n",
        "  elif ground_truth == 'B':\n",
        "    print('Actual cognitive state: Surprised or Startle')\n",
        "  elif ground_truth == 'C':\n",
        "    print('Actual cognitive state: Channelized attention')\n",
        "  else:\n",
        "    print('Actual cognitive state: Diverted attention')\n",
        "\n",
        "pred = function2(df, y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted cognitive state: Channelized attention\n",
            "Actual cognitive state: Channelized attention\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}